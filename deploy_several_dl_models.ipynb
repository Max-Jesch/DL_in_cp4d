{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_watson_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    API_KEY = data['API_KEY']\n",
    "    LOCATION = data['LOCATION']\n",
    "    PROJECT_ID = data['PROJECT_ID']\n",
    "    SPACE_ID = data['SPACE_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# normalize data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis] \n",
    "x_test = x_test[..., tf.newaxis]\n",
    "# create a dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "# create a model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "# compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.fit(train_ds, epochs=5)\n",
    "# evaluate\n",
    "model.evaluate(test_ds)\n",
    "# save the model\n",
    "model.save('mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model to watson studio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_credentials = {\n",
    "    \"apikey\": API_KEY,\n",
    "    \"url\": LOCATION\n",
    "}\n",
    "\n",
    "wml_client = APIClient(wml_credentials)\n",
    "\n",
    "# Watson Studio project\n",
    "wml_client.set.default_project(PROJECT_ID)\n",
    "# Watson Machine Learning space\n",
    "wml_client.set.default_space(SPACE_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tar.gz file with the model\n",
    "def create_tar_gz_file(model_name):\n",
    "    import tarfile\n",
    "    import os\n",
    "    import shutil\n",
    "    # create a tar.gz file with the model\n",
    "    tar = tarfile.open(model_name + '.tar.gz', \"w:gz\")\n",
    "    tar.add(model_name + '.h5')\n",
    "    tar.close()\n",
    "\n",
    "create_tar_gz_file('mnist_model')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of parameters in the model\n",
    "def get_model_parameters(model):\n",
    "    return np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_variables])\n",
    "model_number_of_parameters = get_model_parameters(model)\n",
    "model_number_of_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the size of the model in megabytes with two decimal places\n",
    "def get_model_size(model_name):\n",
    "    import os\n",
    "    return round(os.path.getsize(model_name + '.tar.gz') / 1000000, 2)\n",
    "model_size_mb=get_model_size('mnist_model')\n",
    "str(model_size_mb) + \" MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of model metadata properties\n",
    "wml_client.repository.ModelMetaNames.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sofware_spec_uid = wml_client.software_specifications.get_id_by_name(\"runtime-22.2-py3.10\")\n",
    "\n",
    "\n",
    "\n",
    "metadata = {\n",
    "            wml_client.repository.ModelMetaNames.NAME: 'mnist_small',\n",
    "            wml_client.repository.ModelMetaNames.TYPE: 'tensorflow_2.9',\n",
    "            wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid,\n",
    "            wml_client.repository.ModelMetaNames.SIZE: {'size_in_mb':str(model_size_mb) + \" MB\", 'number_of_parameters':str(model_number_of_parameters)}\n",
    "}\n",
    "\n",
    "published_model = wml_client.repository.store_model(\n",
    "    model=\"mnist_model.tar.gz\",\n",
    "    meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "published_model_uid = wml_client.repository.get_model_id(published_model)\n",
    "model_details = wml_client.repository.get_details(published_model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_details = wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy model to watson machine learning\n",
    "\n",
    "http://ibm-wml-api-pyclient.mybluemix.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    wml_client.deployments.ConfigurationMetaNames.NAME: \"Deployment of external Keras model\",\n",
    "    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "created_deployment = wml_client.deployments.create(published_model_uid, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_uid = wml_client.deployments.get_id(created_deployment)\n",
    "deployment_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = wml_client.deployments.get_scoring_href(created_deployment)\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare one entry from test_ds for prediction\n",
    "def prepare_prediction(image_vector, label):\n",
    "    image_vector = tf.cast(image_vector, tf.float32)\n",
    "    image_vector = image_vector[tf.newaxis, ...]\n",
    "    return image_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_input=prepare_prediction(x_test[0], y_test[0])\n",
    "# do prediction locally\n",
    "results=model.predict(prepared_input[0],prepared_input[1])\n",
    "# print results\n",
    "print(\"predicted digit: {}\".format(np.argmax(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, image in enumerate([x_test[0], x_test[1]]):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_input=prepare_prediction(x_test[0], y_test[0])\n",
    "scoring_payload = {\"input_data\": [{\"values\": prepared_input[0].numpy().tolist()}]}\n",
    "predictions = wml_client.deployments.score(deployment_uid, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted digit: {}\".format(np.argmax(predictions[\"predictions\"][0][\"values\"][0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include scripts for data prepocessing + beautifying the predictions into a function and deploy it with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: figure out how to deploy to different enviroments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create multiple models of different sizes and deploy them + measure the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a prediction for n images and time it\n",
    "def predict_n_images(n):\n",
    "    start = time.time()\n",
    "    for i in range(n):\n",
    "        prepared_input=prepare_prediction(x_test[i], y_test[i])\n",
    "        scoring_payload = {\"input_data\": [{\"values\": prepared_input[0].numpy().tolist()}]}\n",
    "        predictions = wml_client.deployments.score(deployment_uid, scoring_payload)\n",
    "    end = time.time()\n",
    "    print(\"time for {} predictions: {} seconds\".format(n, end-start))\n",
    "    \n",
    "predictions = predict_n_images(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66b4b89368537fbc36e4791e8cc9c0a08c24c4747870e1f05f13f9120129f616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
